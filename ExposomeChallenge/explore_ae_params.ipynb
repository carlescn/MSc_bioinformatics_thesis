{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare some things\n",
    "## Load some modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4fIhSUeUwLYW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from models import get_autoencoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings output (TSNE outputs one very time)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the metabolomic data\n",
    "(alrady min-max normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serum_metab_1</th>\n",
       "      <th>serum_metab_2</th>\n",
       "      <th>serum_metab_3</th>\n",
       "      <th>serum_metab_4</th>\n",
       "      <th>serum_metab_5</th>\n",
       "      <th>serum_metab_6</th>\n",
       "      <th>serum_metab_7</th>\n",
       "      <th>serum_metab_8</th>\n",
       "      <th>serum_metab_9</th>\n",
       "      <th>serum_metab_10</th>\n",
       "      <th>...</th>\n",
       "      <th>urine_metab_35</th>\n",
       "      <th>urine_metab_36</th>\n",
       "      <th>urine_metab_37</th>\n",
       "      <th>urine_metab_38</th>\n",
       "      <th>urine_metab_39</th>\n",
       "      <th>urine_metab_40</th>\n",
       "      <th>urine_metab_41</th>\n",
       "      <th>urine_metab_42</th>\n",
       "      <th>urine_metab_43</th>\n",
       "      <th>urine_metab_44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0.224542</td>\n",
       "      <td>0.205024</td>\n",
       "      <td>0.490470</td>\n",
       "      <td>0.653163</td>\n",
       "      <td>0.515652</td>\n",
       "      <td>0.483009</td>\n",
       "      <td>0.249523</td>\n",
       "      <td>0.340524</td>\n",
       "      <td>0.400406</td>\n",
       "      <td>0.574663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485001</td>\n",
       "      <td>0.628204</td>\n",
       "      <td>0.489431</td>\n",
       "      <td>0.640612</td>\n",
       "      <td>0.391376</td>\n",
       "      <td>0.665946</td>\n",
       "      <td>0.848047</td>\n",
       "      <td>0.360177</td>\n",
       "      <td>0.587031</td>\n",
       "      <td>0.605114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>0.402503</td>\n",
       "      <td>0.549489</td>\n",
       "      <td>0.828354</td>\n",
       "      <td>0.323912</td>\n",
       "      <td>0.431621</td>\n",
       "      <td>0.491824</td>\n",
       "      <td>0.376192</td>\n",
       "      <td>0.348330</td>\n",
       "      <td>0.213731</td>\n",
       "      <td>0.308797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469040</td>\n",
       "      <td>0.816605</td>\n",
       "      <td>0.441328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.494475</td>\n",
       "      <td>0.696170</td>\n",
       "      <td>0.413698</td>\n",
       "      <td>0.396026</td>\n",
       "      <td>0.572658</td>\n",
       "      <td>0.619732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>0.402503</td>\n",
       "      <td>0.556896</td>\n",
       "      <td>0.706195</td>\n",
       "      <td>0.534558</td>\n",
       "      <td>0.544173</td>\n",
       "      <td>0.514375</td>\n",
       "      <td>0.397976</td>\n",
       "      <td>0.856991</td>\n",
       "      <td>0.358113</td>\n",
       "      <td>0.315096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469738</td>\n",
       "      <td>0.627037</td>\n",
       "      <td>0.519383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.326659</td>\n",
       "      <td>0.645060</td>\n",
       "      <td>0.841829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653218</td>\n",
       "      <td>0.665950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>0.462293</td>\n",
       "      <td>0.578889</td>\n",
       "      <td>0.451112</td>\n",
       "      <td>0.448921</td>\n",
       "      <td>0.492050</td>\n",
       "      <td>0.553183</td>\n",
       "      <td>0.372429</td>\n",
       "      <td>0.544806</td>\n",
       "      <td>0.388943</td>\n",
       "      <td>0.545676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457602</td>\n",
       "      <td>0.738061</td>\n",
       "      <td>0.290234</td>\n",
       "      <td>0.177238</td>\n",
       "      <td>0.451808</td>\n",
       "      <td>0.487007</td>\n",
       "      <td>0.759121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.678092</td>\n",
       "      <td>0.729031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>0.247137</td>\n",
       "      <td>0.571595</td>\n",
       "      <td>0.568414</td>\n",
       "      <td>0.417697</td>\n",
       "      <td>0.432269</td>\n",
       "      <td>0.553183</td>\n",
       "      <td>0.531642</td>\n",
       "      <td>0.534388</td>\n",
       "      <td>0.536561</td>\n",
       "      <td>0.704749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452021</td>\n",
       "      <td>0.639165</td>\n",
       "      <td>0.329798</td>\n",
       "      <td>0.354477</td>\n",
       "      <td>0.250210</td>\n",
       "      <td>0.702331</td>\n",
       "      <td>0.778121</td>\n",
       "      <td>0.345500</td>\n",
       "      <td>0.554585</td>\n",
       "      <td>0.661642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      serum_metab_1  serum_metab_2  serum_metab_3  serum_metab_4  \\\n",
       "430        0.224542       0.205024       0.490470       0.653163   \n",
       "1187       0.402503       0.549489       0.828354       0.323912   \n",
       "940        0.402503       0.556896       0.706195       0.534558   \n",
       "936        0.462293       0.578889       0.451112       0.448921   \n",
       "788        0.247137       0.571595       0.568414       0.417697   \n",
       "\n",
       "      serum_metab_5  serum_metab_6  serum_metab_7  serum_metab_8  \\\n",
       "430        0.515652       0.483009       0.249523       0.340524   \n",
       "1187       0.431621       0.491824       0.376192       0.348330   \n",
       "940        0.544173       0.514375       0.397976       0.856991   \n",
       "936        0.492050       0.553183       0.372429       0.544806   \n",
       "788        0.432269       0.553183       0.531642       0.534388   \n",
       "\n",
       "      serum_metab_9  serum_metab_10  ...  urine_metab_35  urine_metab_36  \\\n",
       "430        0.400406        0.574663  ...        0.485001        0.628204   \n",
       "1187       0.213731        0.308797  ...        0.469040        0.816605   \n",
       "940        0.358113        0.315096  ...        0.469738        0.627037   \n",
       "936        0.388943        0.545676  ...        0.457602        0.738061   \n",
       "788        0.536561        0.704749  ...        0.452021        0.639165   \n",
       "\n",
       "      urine_metab_37  urine_metab_38  urine_metab_39  urine_metab_40  \\\n",
       "430         0.489431        0.640612        0.391376        0.665946   \n",
       "1187        0.441328        0.000000        0.494475        0.696170   \n",
       "940         0.519383        0.000000        0.326659        0.645060   \n",
       "936         0.290234        0.177238        0.451808        0.487007   \n",
       "788         0.329798        0.354477        0.250210        0.702331   \n",
       "\n",
       "      urine_metab_41  urine_metab_42  urine_metab_43  urine_metab_44  \n",
       "430         0.848047        0.360177        0.587031        0.605114  \n",
       "1187        0.413698        0.396026        0.572658        0.619732  \n",
       "940         0.841829        0.000000        0.653218        0.665950  \n",
       "936         0.759121        0.000000        0.678092        0.729031  \n",
       "788         0.778121        0.345500        0.554585        0.661642  \n",
       "\n",
       "[5 rows x 221 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metabol_exprs = pd.read_csv(\"ExposomeChallengeData/datasets/metabol_joint_exprs_minmax.csv\", index_col=0)\n",
    "metabol_exprs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabol_exprs = metabol_exprs.to_numpy()\n",
    "np.random.shuffle(metabol_exprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data set: (1152, 221)\n",
      "Number of data points: 254592\n"
     ]
    }
   ],
   "source": [
    "num_data_points = np.multiply(*metabol_exprs.shape)\n",
    "print(\"Shape of the data set:\", metabol_exprs.shape)\n",
    "print(\"Number of data points:\", num_data_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the categorical variables\n",
    "(subset of phenotype and covariates data, already codified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birth_weight</th>\n",
       "      <th>iq</th>\n",
       "      <th>behaviour</th>\n",
       "      <th>asthma</th>\n",
       "      <th>bmi</th>\n",
       "      <th>cohort</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>education</th>\n",
       "      <th>native</th>\n",
       "      <th>parity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   birth_weight  iq  behaviour  asthma  bmi  cohort  age  sex  education  \\\n",
       "1             3   0          3       0    1       3    1    0          1   \n",
       "2             3   1          3       0    1       3    2    0          2   \n",
       "3             3   0          3       1    3       3    1    0          2   \n",
       "4             1   2          3       0    1       1    4    1          0   \n",
       "5             3   0          1       0    1       2    4    0          0   \n",
       "\n",
       "   native  parity  \n",
       "1       2       0  \n",
       "2       2       1  \n",
       "3       2       1  \n",
       "4       2       1  \n",
       "5       2       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phenotype_cat = pd.read_csv(\"ExposomeChallengeData/datasets/phenotype_cat.csv\", index_col=0)\n",
    "covariates_cat = pd.read_csv(\"ExposomeChallengeData/datasets/covariates_cat.csv\", index_col=0)\n",
    "classes = pd.concat([phenotype_cat, covariates_cat], axis=1)\n",
    "classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of class variables: 11\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of class variables:\", classes.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try AE with different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_callback(epoch, logs):\n",
    "    global p\n",
    "    global c_last\n",
    "    \n",
    "    if (epoch+1) % SCHEDULE == 0:\n",
    "        q = model_dec.soft_assignment(metabol_exprs)\n",
    "        p = compute_p(q)\n",
    "        \n",
    "        c_new = q.numpy().argmax(1)\n",
    "        delta = compute_delta(c_new, c_last)\n",
    "        c_last = np.copy(c_new)\n",
    "        # print(f\"Delta: {delta:.3f}\")\n",
    "        if (delta < DELTA_THRESHOLD):\n",
    "            model_dec.stop_training = True\n",
    "            \n",
    "callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=dec_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1\n",
    "MOMENTUM = 0.8\n",
    "optimizer = keras.optimizers.SGD(learning_rate=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "INPUT_DIM = metabol_exprs.shape[1]\n",
    "LATENT_DIM = 5\n",
    "N_CLUSTERS = LATENT_DIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate layers number and dimentions\n",
    "\n",
    "Let's try different numbers and dimentions of intermediate layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 2048) [data/params ratio: 0.1] [loss: 0.0134, val_loss: 0.0134, ratio: 0.9999]\n",
      "(64, 32) [data/params ratio: 7.7] [loss: 0.0138, val_loss: 0.0138, ratio: 0.9966]\n",
      "(32, 16) [data/params ratio: 16.3] [loss: 0.0155, val_loss: 0.0152, ratio: 1.0155]\n",
      "(16, 4) [data/params ratio: 33.9] [loss: 0.0161, val_loss: 0.0158, ratio: 1.0227]\n",
      "(16, 16, 64) [data/params ratio: 23.8] [loss: 0.0164, val_loss: 0.0160, ratio: 1.0278]\n",
      "(16, 16, 128) [data/params ratio: 18.9] [loss: 0.0157, val_loss: 0.0155, ratio: 1.0170]\n",
      "(16, 16, 256) [data/params ratio: 13.3] [loss: 0.0158, val_loss: 0.0155, ratio: 1.0178]\n",
      "(32, 32, 64) [data/params ratio: 11.9] [loss: 0.0152, val_loss: 0.0150, ratio: 1.0145]\n",
      "(32, 32, 128) [data/params ratio: 9.7] [loss: 0.0155, val_loss: 0.0153, ratio: 1.0147]\n",
      "(32, 32, 256) [data/params ratio: 7.1] [loss: 0.0156, val_loss: 0.0154, ratio: 1.0147]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "INTERMEDIATE_DIMS = [(512, 512, 2048), # same as in MNIST, for reference\n",
    "                     (64, 32),\n",
    "                     (32, 16),\n",
    "                     (16, 4),\n",
    "                     (16, 16, 64),\n",
    "                     (16, 16, 128),\n",
    "                     (16, 16, 256),\n",
    "                     (32, 32, 64),\n",
    "                     (32, 32, 128),\n",
    "                     (32, 32, 256)\n",
    "                    ]\n",
    "\n",
    "# Try every combination of dimention 5 times, \n",
    "# then get the mean of the results\n",
    "for dims in INTERMEDIATE_DIMS:\n",
    "    loss = []\n",
    "    val_loss = []\n",
    "    loss_ratio = []\n",
    "    for i in np.arange(5):\n",
    "        model_ae = get_autoencoder_model(INPUT_DIM, LATENT_DIM, dims)\n",
    "        data_params_ratio = num_data_points / (model_ae.encoder.count_params() + \n",
    "                                               model_ae.decoder.count_params())\n",
    "        if i == 0:\n",
    "            print(f'{dims} [data/params ratio: {data_params_ratio:.1f}]', end=\" \")\n",
    "\n",
    "        model_ae.compile(optimizer=optimizer, loss=\"mse\")\n",
    "        history = model_ae.fit(metabol_exprs, metabol_exprs,\n",
    "                               epochs=EPOCHS,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               validation_split=0.2,\n",
    "                               verbose=0)\n",
    "        loss.append(history.history['loss'][-1])\n",
    "        val_loss.append(history.history['val_loss'][-1])\n",
    "        loss_ratio.append(loss[-1] / val_loss[-1])\n",
    "\n",
    "    print(f\"[loss: {np.mean(loss):.4f}, val_loss: {np.mean(val_loss):.4f}, ratio: {np.mean(loss_ratio):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best loss is achieved with only two intermediate layers (dims: (64,32)), but the data/params ratio is very low and this can make the model easily overfit.\n",
    "\n",
    "The model with dimentions (16, 16, 128) gets a slightly lower loss but with a better data/params ratio.\n",
    "\n",
    "By training for more epochs, de difference in loss can be minimized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 32) [data/params ratio: 7.7] [loss: 0.0131, val_loss: 0.0131, ratio: 0.9982]\n",
      "(16, 16, 128) [data/params ratio: 18.9] [loss: 0.0138, val_loss: 0.0138, ratio: 1.0004]\n",
      "(32, 32, 64) [data/params ratio: 11.9] [loss: 0.0128, val_loss: 0.0128, ratio: 1.0002]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "INTERMEDIATE_DIMS = [(64, 32),\n",
    "                     (16, 16, 128),\n",
    "                     (32, 32, 64),\n",
    "                    ]\n",
    "\n",
    "# Try every combination of dimention 5 times, \n",
    "# then get the mean of the results\n",
    "for dims in INTERMEDIATE_DIMS:\n",
    "    loss = []\n",
    "    val_loss = []\n",
    "    loss_ratio = []\n",
    "    for i in np.arange(5):\n",
    "        model_ae = get_autoencoder_model(INPUT_DIM, LATENT_DIM, dims)\n",
    "        data_params_ratio = num_data_points / (model_ae.encoder.count_params() + \n",
    "                                               model_ae.decoder.count_params())\n",
    "        if i == 0:\n",
    "            print(f'{dims} [data/params ratio: {data_params_ratio:.1f}]', end=\" \")\n",
    "\n",
    "        model_ae.compile(optimizer=optimizer, loss=\"mse\")\n",
    "        history = model_ae.fit(metabol_exprs, metabol_exprs,\n",
    "                               epochs=EPOCHS,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               validation_split=0.2,\n",
    "                               verbose=0)\n",
    "        loss.append(history.history['loss'][-1])\n",
    "        val_loss.append(history.history['val_loss'][-1])\n",
    "        loss_ratio.append(loss[-1] / val_loss[-1])\n",
    "\n",
    "    print(f\"[loss: {np.mean(loss):.4f}, val_loss: {np.mean(val_loss):.4f}, ratio: {np.mean(loss_ratio):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll select the combination (16, 16, 128), since it achieves the better relation between data/params ratio and loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch size\n",
    "\n",
    "Let's now try different batch sizes to see if there is are any big differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 16 [loss: 0.0151, val_loss: 0.0149, ratio: 1.0099]\n",
      "batch size: 32 [loss: 0.0160, val_loss: 0.0156, ratio: 1.0195]\n",
      "batch size: 64 [loss: 0.0179, val_loss: 0.0171, ratio: 1.0464]\n",
      "batch size: 128 [loss: 0.0192, val_loss: 0.0179, ratio: 1.0686]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "INTERMEDIATE_DIMS = (16, 16, 128)\n",
    "BATCH_SIZES = (16, 32, 64, 128)\n",
    "\n",
    "# Try every batch size 5 times, \n",
    "# then get the mean of the results\n",
    "for batch_size in BATCH_SIZES:\n",
    "    loss = []\n",
    "    val_loss = []\n",
    "    loss_ratio = []\n",
    "    print(f'batch size: {batch_size}', end=\" \")\n",
    "    for i in np.arange(5):\n",
    "        model_ae = get_autoencoder_model(INPUT_DIM, LATENT_DIM, INTERMEDIATE_DIMS)\n",
    "        model_ae.compile(optimizer=optimizer, loss=\"mse\")\n",
    "        history = model_ae.fit(metabol_exprs, metabol_exprs,\n",
    "                               epochs=EPOCHS,\n",
    "                               batch_size=batch_size,\n",
    "                               validation_split=0.2,\n",
    "                               verbose=0)\n",
    "        loss.append(history.history['loss'][-1])\n",
    "        val_loss.append(history.history['val_loss'][-1])\n",
    "        loss_ratio.append(loss[-1] / val_loss[-1])\n",
    "\n",
    "    print(f\"[loss: {np.mean(loss):.4f}, val_loss: {np.mean(val_loss):.4f}, ratio: {np.mean(loss_ratio):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smaller batch sizes achieve a lower loss, but also the training process takes longer.\n",
    "\n",
    "Both things can be contrarrested by selecting a different amount of epochs. So it does'nt seem to be criticall.\n",
    "\n",
    "I'll select a batch size of 32 and vary the number of epochs depending on how long it takes for the loss to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected parameters\n",
    "\n",
    "Based on the results, I decided to select the following parameters:\n",
    "- Intermediate dimentions: (16, 16, 128)\n",
    "- Batch size: 32"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
