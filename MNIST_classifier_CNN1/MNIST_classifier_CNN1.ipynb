{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6Cf3oHg1Kjb"
   },
   "source": [
    "# Learning the basics of Keras, training a CNN classifier on the MNIST data set.\n",
    "\n",
    "With this exercise I'm trying to learn the basics of training an ANN with Keras. I will define and train a CNN classifier on the MNIST data set.\n",
    "\n",
    "I will try different configurations from intuition only (I won't be methodic), based on what I learned from the book \"Deep Learning with Python\" (available at https://livebook.manning.com/book/deep-learning-with-python-second-edition/deep-learning-with-python/).\n",
    "\n",
    "This is a personal exercise so I won't explain everything in detail either.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LykZK_G3YswF"
   },
   "source": [
    "# Import libraries\n",
    "Import the necessary libraries to run this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T17:30:42.678522Z",
     "iopub.status.busy": "2022-09-25T17:30:42.678028Z",
     "iopub.status.idle": "2022-09-25T17:30:47.064570Z",
     "shell.execute_reply": "2022-09-25T17:30:47.063286Z",
     "shell.execute_reply.started": "2022-09-25T17:30:42.678403Z"
    },
    "id": "4fIhSUeUwLYW"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python import train\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WESxeas3Y3OV"
   },
   "source": [
    "# Load and prepare the MNIST data set\n",
    "\n",
    "Load de MNIST data set form Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-09-25T17:30:47.067631Z",
     "iopub.status.busy": "2022-09-25T17:30:47.066633Z",
     "iopub.status.idle": "2022-09-25T17:30:47.618449Z",
     "shell.execute_reply": "2022-09-25T17:30:47.617249Z",
     "shell.execute_reply.started": "2022-09-25T17:30:47.067598Z"
    },
    "id": "ro3n-FfV-N3-",
    "outputId": "345e9d76-9d4e-42a4-cb67-8eea4d7086d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = (mnist.load_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-YXr54xZgwO"
   },
   "source": [
    "Show the first image and some properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "Asc_p1g0lftZ",
    "outputId": "a53fb00f-2b93-4d1a-9588-0325cb3281ee"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n",
      "Shape: (28, 28)\n",
      "Max/min: 255 0\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(x_train[0].reshape(28,28))\n",
    "plt.axis('off')\n",
    "plt.set_cmap('gray')\n",
    "plt.title(\"First item of train\")\n",
    "plt.show()\n",
    "print(\"Label:\", y_train[0])\n",
    "print(\"Shape:\", x_train[0].shape)\n",
    "print(\"Max/min:\", x_train[0].max(), x_train[0].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQ6XJiPkaxyq"
   },
   "source": [
    "Add one dimmension to the train and test data to fit the expected shape of the network input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T17:30:47.620325Z",
     "iopub.status.busy": "2022-09-25T17:30:47.620056Z",
     "iopub.status.idle": "2022-09-25T17:30:47.750585Z",
     "shell.execute_reply": "2022-09-25T17:30:47.749474Z",
     "shell.execute_reply.started": "2022-09-25T17:30:47.620300Z"
    },
    "id": "zBAsXZJ-Ct0a"
   },
   "outputs": [],
   "source": [
    "x_train = x_train[:, :, :, np.newaxis]\n",
    "x_test = x_test[:, :, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFtXNSEnceUs"
   },
   "source": [
    "Separate a validation data set from the train data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T17:30:47.754238Z",
     "iopub.status.busy": "2022-09-25T17:30:47.753768Z",
     "iopub.status.idle": "2022-09-25T17:30:47.760342Z",
     "shell.execute_reply": "2022-09-25T17:30:47.759109Z",
     "shell.execute_reply.started": "2022-09-25T17:30:47.754192Z"
    },
    "id": "k_6NP2tjIYXh"
   },
   "outputs": [],
   "source": [
    "size_val = 10000\n",
    "size_train = x_train.shape[0] - size_val\n",
    "\n",
    "x_val = x_train[size_train:]\n",
    "y_val = y_train[size_train:]\n",
    "\n",
    "x_train = x_train[:size_train]\n",
    "y_train = y_train[:size_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyoWCGNvcuma"
   },
   "source": [
    "We now have 50.000 cases for the train set, 10.000 cases for the validation set and 10.000 cases for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDRtdFLYct3a",
    "outputId": "0f058919-f622-4358-94e8-632a85186332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (50000, 28, 28, 1)\n",
      "train labels shape: (50000,) \n",
      "\n",
      "validation data shape: (10000, 28, 28, 1)\n",
      "validation labels shape: (10000,) \n",
      "\n",
      "test data shape: (10000, 28, 28, 1)\n",
      "test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train data shape:\", x_train.shape)\n",
    "print(\"train labels shape:\", y_train.shape, \"\\n\")\n",
    "\n",
    "print(\"validation data shape:\", x_val.shape)\n",
    "print(\"validation labels shape:\", y_val.shape, \"\\n\")\n",
    "\n",
    "print(\"test data shape:\", x_test.shape)\n",
    "print(\"test labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiXhone_d-4p"
   },
   "source": [
    "# Prepare some reusable code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpzcNCmlewNd"
   },
   "source": [
    "Define a callbacks list that we will use whan training every model. We want to:\n",
    "- Stop after 10 epochs if there is no improvement.*\n",
    "- Save the last best model.\n",
    "\n",
    "**\\* Note: I've commented out the early stopping part since some models weren't able to overfit this way.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T17:30:47.771476Z",
     "iopub.status.busy": "2022-09-25T17:30:47.771183Z",
     "iopub.status.idle": "2022-09-25T17:30:47.777526Z",
     "shell.execute_reply": "2022-09-25T17:30:47.776244Z",
     "shell.execute_reply.started": "2022-09-25T17:30:47.771451Z"
    },
    "id": "YHiyeUlYHk0o"
   },
   "outputs": [],
   "source": [
    "def get_callbacks_list(fname=\"model.keras\"):\n",
    "    callbacks_list = [\n",
    "        # stop after 10 epochs after overfitting\n",
    "        # keras.callbacks.EarlyStopping(\n",
    "        #     monitor=\"val_accuracy\",\n",
    "        #     patience=10,\n",
    "        # ),\n",
    "        # save the best model in training\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            fname,\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_loss\",\n",
    "        )\n",
    "    ]\n",
    "    return callbacks_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FReFvpvforX"
   },
   "source": [
    "Define a function that will take care of the compilation, training and testing for every model we define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T17:30:50.832655Z",
     "iopub.status.busy": "2022-09-25T17:30:50.831414Z",
     "iopub.status.idle": "2022-09-25T17:30:50.841172Z",
     "shell.execute_reply": "2022-09-25T17:30:50.840215Z",
     "shell.execute_reply.started": "2022-09-25T17:30:50.832610Z"
    },
    "id": "GkAamFgBGHcl"
   },
   "outputs": [],
   "source": [
    "def new_model(inputs, outputs,\n",
    "              model_name = \"model\",\n",
    "              summary = False,\n",
    "              plot = False,\n",
    "              epochs = 100,\n",
    "              optimizer = \"rmsprop\",\n",
    "              loss = \"sparse_categorical_crossentropy\", \n",
    "              metrics = [\"accuracy\"],\n",
    "              ):\n",
    "\n",
    "    # Clear keras session (force to initialize new model from scratch)\n",
    "    K.clear_session()\n",
    "\n",
    "    # Create new model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "\n",
    "    # Show some info\n",
    "    print(\"Model name: \" + model.name)\n",
    "    print(\"Total number of parameters: \" + str(model.count_params()))\n",
    "    if summary: model.summary()\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = loss,\n",
    "                  metrics = metrics)\n",
    "\n",
    "    # Train model\n",
    "    fname = model_name + \".keras\"\n",
    "    callbacks_list = get_callbacks_list(fname)\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        epochs = epochs,\n",
    "                        batch_size = 64, \n",
    "                        validation_data = (x_val, y_val),\n",
    "                        callbacks = callbacks_list)\n",
    "\n",
    "    # Show validation and loss plots\n",
    "    if plot: plot_val_loss(history)\n",
    "\n",
    "    # Load best model and evaluate it with the test data set\n",
    "    model = keras.models.load_model(fname)\n",
    "    _, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"Test accuracy: \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIUC-jFIiDxy"
   },
   "source": [
    "Define two layers that we will use on (almost) every model. They will take care of:\n",
    "- Image preprocessing:\n",
    "  - Resizing (not actually necessary in this case)\n",
    "  - Rescaling\n",
    "- Data augmentation:\n",
    "  - Random rotation\n",
    "  - Random zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "62CUilQlt7WS"
   },
   "outputs": [],
   "source": [
    "resize_and_rescale = keras.Sequential([\n",
    "    layers.Resizing(28, 28),\n",
    "    layers.Rescaling(1./255),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9-PEYujrxG36"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rqh_W6IgeaKm"
   },
   "source": [
    "Define a function that will take a history object and draw the accuracy and loss plots of the train and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T17:30:47.761870Z",
     "iopub.status.busy": "2022-09-25T17:30:47.761564Z",
     "iopub.status.idle": "2022-09-25T17:30:47.769923Z",
     "shell.execute_reply": "2022-09-25T17:30:47.768732Z",
     "shell.execute_reply.started": "2022-09-25T17:30:47.761845Z"
    },
    "id": "jEULCLbqPLfc"
   },
   "outputs": [],
   "source": [
    "def plot_val_loss(history):\n",
    "\n",
    "    # Extract info from history object \n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(1, len(acc) +1)\n",
    "\n",
    "    # Accuracy\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(epochs, acc, \"bo\", label=\"Training\")\n",
    "    ax.plot(epochs, val_acc, \"b\", label=\"Validation\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Accuracy\", color=\"blue\")\n",
    "\n",
    "    # Loss\n",
    "    ax2=ax.twinx()\n",
    "    ax2.plot(epochs, loss, \"ro\", label=\"Training\")\n",
    "    ax2.plot(epochs, val_loss, \"r\", label=\"Validation\")\n",
    "    ax2.set_ylabel(\"Loss\", color=\"red\")\n",
    "\n",
    "    fig.legend(bbox_to_anchor=(0.9, 0.6))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmmpFZuMjUBS"
   },
   "source": [
    "# Try some models\n",
    "\n",
    "Now we can define and test some models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "409CTAUtsexV"
   },
   "source": [
    "## Simple convolutional network\n",
    "\n",
    "We'll start with a very simple version of a CNN model:\n",
    "- 3 convolutional layers\n",
    "  - kernel size = 3\n",
    "  - number of filters = 32, 64 and 128\n",
    "- A single dense layer\n",
    "\n",
    "We achieve an **accuracy of 0.9920** on the test data. Not bad!\n",
    "\n",
    "Lets try to improve it building a progressively more complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "code",
    "id": "rliP4fkP0XMR"
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT TO RUN THIS MODEL\n",
    "\n",
    "# model_name=\"simple_conv\"\n",
    "\n",
    "# inputs = keras.Input(shape=(28,28,1), name=\"inputs\")\n",
    "# x = resize_and_rescale(inputs)\n",
    "\n",
    "# filters = [32, 64, 128]\n",
    "# for f in filters:\n",
    "#     x = layers.Conv2D(f, 5, activation=\"relu\", name=\"conv\"+str(f)) (x)\n",
    "\n",
    "# x = layers.Flatten(name=\"flatten\") (x)\n",
    "# outputs = layers.Dense(10, activation=\"softmax\", name=\"outputs\") (x)\n",
    "\n",
    "# new_model(inputs, outputs,summary=True, plot=True, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqdNfmULljEW"
   },
   "source": [
    "## Add max pooling\n",
    "- 3 convolutional layers\n",
    "  - kernel size = 3\n",
    "  - number of filters = 32, 64 and 128\n",
    "- ***Max pooling after each convolutional layer***\n",
    "  - ***strides = 2***\n",
    "- A single dense layer\n",
    "\n",
    "**Test accuracy: 0.9925**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_HK8nJTB8cAM"
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT TO RUN THIS MODEL\n",
    "\n",
    "# model_name=\"maxpool\"\n",
    "\n",
    "# inputs = keras.Input(shape=(28,28,1), name=\"inputs\")\n",
    "# x = resize_and_rescale(inputs)\n",
    "\n",
    "# filters = [32, 64, 128]\n",
    "# for f in filters:\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\", name=\"conv\"+str(f)) (x)\n",
    "#     x = layers.MaxPooling2D(2, name=\"maxpool\"+str(f)) (x)\n",
    "\n",
    "# x = layers.Flatten(name=\"flatten\") (x)\n",
    "# outputs = layers.Dense(10, activation=\"softmax\", name=\"outputs\") (x)\n",
    "\n",
    "# new_model(inputs, outputs,summary=True, plot=True, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYD5uyofn8K9"
   },
   "source": [
    "## Add dropout\n",
    "- 3 convolutional layers\n",
    "  - kernel size = 3\n",
    "  - number of filters = 32, 64 and 128\n",
    "- Max pooling after each convolutional layer\n",
    "  - strides = 2\n",
    "- ***Dropout layer after each convolutional layer***\n",
    "  - ***dropout = 0.4***\n",
    "- A single dense layer\n",
    "\n",
    "**Test accuracy: 0.9930**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7TIFZi2lQEh"
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT TO RUN THIS MODEL\n",
    "\n",
    "# model_name=\"dropout\"\n",
    "\n",
    "# inputs = keras.Input(shape=(28,28,1), name=\"inputs\")\n",
    "# x = resize_and_rescale(inputs)\n",
    "\n",
    "# filters = [32, 64, 128]\n",
    "# for f in filters:\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\", name=\"conv\"+str(f)) (x)\n",
    "#     x = layers.MaxPooling2D(2, name=\"maxpool\"+str(f)) (x)\n",
    "#     x = layers.Dropout(0.4) (x)\n",
    "\n",
    "# x = layers.Flatten(name=\"flatten\") (x)\n",
    "# outputs = layers.Dense(10, activation=\"softmax\", name=\"outputs\") (x)\n",
    "\n",
    "# new_model(inputs, outputs,summary=True, plot=True, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tE-kTjBTo_xN"
   },
   "source": [
    "## Two dense layers\n",
    "- 3 convolutional layers\n",
    "  - kernel size = 3\n",
    "  - number of filters = 32, 64 and 128\n",
    "- Max pooling after each convolutional layer\n",
    "  - strides = 2\n",
    "- Dropout layer after each convolutional layer\n",
    "  - dropout = 0.4\n",
    "- ***Two dense layers***\n",
    "  - ***hidden - 128 neurons***\n",
    "  - output - 10 neurons\n",
    "\n",
    "**Test accuracy: 0.9925**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eP_WVV8ClQEh"
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT TO RUN THIS MODEL\n",
    "\n",
    "# model_name=\"two_dense\"\n",
    "\n",
    "# inputs = keras.Input(shape=(28,28,1), name=\"inputs\")\n",
    "# x = resize_and_rescale(inputs)\n",
    "\n",
    "# filters = [32, 64, 128]\n",
    "# for f in filters:\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\", name=\"conv\"+str(f)) (x)\n",
    "#     x = layers.MaxPooling2D(2, name=\"maxpool\"+str(f)) (x)\n",
    "#     x = layers.Dropout(0.4) (x)\n",
    "\n",
    "# x = layers.Flatten(name=\"flatten\") (x)\n",
    "# x = layers.Dense(128, activation=\"relu\", name=\"dense\") (x)\n",
    "# x = layers.Dropout(0.4) (x)\n",
    "# outputs = layers.Dense(10, activation=\"softmax\", name=\"outputs\") (x)\n",
    "\n",
    "# new_model(inputs, outputs,summary=True, plot=True, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Imn3_ly-qRih"
   },
   "source": [
    "## Dump the hidden layer. Replace max pooling with convolutional (strides=2)\n",
    "\n",
    "The max pooling layers have no learnable parameters. We can replace them with convolutional layers with strides=2 to obtain the same resolution reduction, but with learnable parameters.\n",
    "\n",
    "- 3 convolutional layers\n",
    "  - kernel size = 3\n",
    "  - number of filters = 32, 64 and 128\n",
    "- ***Conv. layer with strides = 2 instead of max pooling layers, after each convolutional layer***\n",
    "  - strides = 2\n",
    "- Dropout layer after each ***stack***\n",
    "  - dropout = 0.4\n",
    "- ***One single dense layer***\n",
    "\n",
    "**Test accuracy: 0.9932**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7s5U2T2lQEi"
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT TO RUN THIS MODEL\n",
    "\n",
    "# model_name=\"strides\"\n",
    "\n",
    "# inputs = keras.Input(shape=(28,28,1), name=\"inputs\")\n",
    "# x = resize_and_rescale(inputs)\n",
    "\n",
    "# filters = [32, 64, 128]\n",
    "# for f in filters:\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\", name=\"conv\"+str(f)) (x)\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", strides=2, activation=\"relu\", name=\"stride\"+str(f)) (x)\n",
    "#     x = layers.Dropout(0.4) (x)\n",
    "\n",
    "# x = layers.Flatten(name=\"flatten\") (x)\n",
    "# outputs = layers.Dense(10, activation=\"softmax\", name=\"outputs\") (x)\n",
    "\n",
    "# new_model(inputs, outputs,summary=True, plot=True, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6y7HJW1tMHw"
   },
   "source": [
    "## Add batch normalization\n",
    "\n",
    "- 3 convolutional layers\n",
    "  - kernel size = 3\n",
    "  - number of filters = 32, 64 and 128\n",
    "- Conv. layer with strides = 2 instead of max pooling layers, after each convolutional layer\n",
    "  - strides = 2\n",
    "- ***Batch normalization after each convolutional layer***\n",
    "- Dropout layer after each stack\n",
    "  - dropout = 0.4\n",
    "- A single dense layer\n",
    "\n",
    "**Test accuracy: 0.9939**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T18:14:56.650066Z",
     "iopub.status.busy": "2022-09-25T18:14:56.649818Z",
     "iopub.status.idle": "2022-09-25T18:21:22.395632Z",
     "shell.execute_reply": "2022-09-25T18:21:22.394659Z",
     "shell.execute_reply.started": "2022-09-25T18:14:56.650043Z"
    },
    "id": "VbtddFHklQEi"
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT TO RUN THIS MODEL\n",
    "\n",
    "# model_name=\"batchnorm\"\n",
    "\n",
    "# inputs = keras.Input(shape=(28,28,1), name=\"inputs\")\n",
    "# x = resize_and_rescale(inputs)\n",
    "\n",
    "# filters = [32, 64, 128]\n",
    "# for i,f in enumerate(filters):\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\", name=\"conv\"+str(f)) (x)\n",
    "#     x = layers.BatchNormalization(name=\"conv_norm\"+str(f)) (x)\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", strides=2, activation=\"relu\", name=\"strides\"+str(f)) (x)\n",
    "#     x = layers.BatchNormalization(name=\"strides_norm\"+str(f)) (x)\n",
    "#     x = layers.Dropout(0.4) (x)\n",
    "\n",
    "# x = layers.Flatten(name=\"flatten\") (x)\n",
    "# outputs = layers.Dense(10, activation=\"softmax\", name=\"outputs\") (x)\n",
    "\n",
    "# new_model(inputs, outputs,summary=True, plot=True, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1TBpoSCtwpw"
   },
   "source": [
    "## Add another convolutional layer to each stack\n",
    "\n",
    "- ***3 stacks of two convolutional layers***\n",
    "  - kernel size = 3\n",
    "  - number of filters = 32, 64 and 128\n",
    "- Conv. layer with strides = 2 instead of max pooling layers, after each stack\n",
    "  - strides = 2\n",
    "- Batch normalization after each stack\n",
    "- Dropout layer after each stack\n",
    "  - dropout = 0.4\n",
    "- A single dense layer\n",
    "\n",
    "**Test accuracy: 0.9929**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T18:08:33.835942Z",
     "iopub.status.busy": "2022-09-25T18:08:33.835018Z",
     "iopub.status.idle": "2022-09-25T18:14:56.647417Z",
     "shell.execute_reply": "2022-09-25T18:14:56.646255Z",
     "shell.execute_reply.started": "2022-09-25T18:08:33.835916Z"
    },
    "id": "LvysujuAlQEi"
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT TO RUN THIS MODEL\n",
    "\n",
    "# model_name=\"conv_stacks\"\n",
    "\n",
    "# inputs = keras.Input(shape=(28,28,1), name=\"inputs\")\n",
    "# x = resize_and_rescale(inputs)\n",
    "\n",
    "# filters = [32, 64, 128]\n",
    "# for i,f in enumerate(filters):\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\", name=\"conva\"+str(f)) (x)\n",
    "#     x = layers.BatchNormalization(name=\"conva_norm\"+str(f)) (x)\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\", name=\"convb\"+str(f)) (x)\n",
    "#     x = layers.BatchNormalization(name=\"convb_norm\"+str(f)) (x)\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", strides=2, activation=\"relu\", name=\"strides\"+str(f)) (x)\n",
    "#     x = layers.BatchNormalization(name=\"strides_norm\"+str(f)) (x)\n",
    "#     x = layers.Dropout(0.4) (x)\n",
    "\n",
    "# x = layers.Flatten(name=\"flatten\") (x)\n",
    "# outputs = layers.Dense(10, activation=\"softmax\", name=\"outputs\") (x)\n",
    "\n",
    "# new_model(inputs, outputs,summary=True, plot=True, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pPDTfLrukpo"
   },
   "source": [
    "## Add a residual connection\n",
    "\n",
    "- 3 stacks of two convolutional layers\n",
    "  - kernel size = 3\n",
    "  - number of filters = 32, 64 and 128\n",
    "- Conv. layer with strides = 2 instead of max pooling layers, after each stack\n",
    "  - strides = 2\n",
    "- Batch normalization after each stack\n",
    "- Dropout layer after each stack\n",
    "  - dropout = 0.4\n",
    "- ***A residual layer circumventing each stack***\n",
    "- A single dense layer\n",
    "\n",
    "**Test accuracy: 0.9937**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-25T18:23:05.787773Z",
     "iopub.status.busy": "2022-09-25T18:23:05.787377Z",
     "iopub.status.idle": "2022-09-25T18:37:33.584342Z",
     "shell.execute_reply": "2022-09-25T18:37:33.583489Z",
     "shell.execute_reply.started": "2022-09-25T18:23:05.787732Z"
    },
    "id": "IKl_ZVRZlQEj"
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT TO RUN THIS MODEL\n",
    "\n",
    "# model_name=\"residual\"\n",
    "\n",
    "# inputs = keras.Input(shape=(28,28,1), name=\"inputs\")\n",
    "# x = resize_and_rescale(inputs)\n",
    "\n",
    "# filters = [32, 64, 128]\n",
    "# for i,f in enumerate(filters):\n",
    "#     residual = x\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\", name=\"convA\"+str(f)) (x)\n",
    "#     x = layers.BatchNormalization(name=\"convA_norm\"+str(f)) (x)\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\", name=\"convB\"+str(f)) (x)\n",
    "#     x = layers.BatchNormalization(name=\"convB_norm\"+str(f)) (x)\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", strides=2, activation=\"relu\", name=\"strides\"+str(f)) (x)\n",
    "#     x = layers.BatchNormalization(name=\"strides_norm\"+str(f)) (x)\n",
    "#     x = layers.Dropout(0.4) (x)\n",
    "#     residual = layers.Conv2D(f, 1, padding=\"same\", strides=2, name=\"convR\"+str(f)) (residual)\n",
    "#     x = layers.add([x, residual], name=\"add\"+str(f))\n",
    "    \n",
    "# x = layers.Flatten(name=\"flatten\") (x)\n",
    "# outputs = layers.Dense(10, activation=\"softmax\", name=\"outputs\") (x)\n",
    "\n",
    "# new_model(inputs, outputs,summary=True, plot=True, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DD3aFw9cvAR-"
   },
   "source": [
    "## Add data augmentation\n",
    "\n",
    "- ***Data augmentation layer***\n",
    "    - ***Random rotation***\n",
    "    - ***Random zoom***\n",
    "- 3 stacks of two convolutional layers\n",
    "  - kernel size = 3\n",
    "  - number of filters = 32, 64 and 128\n",
    "- Conv. layer with strides = 2 instead of max pooling layers, after each stack\n",
    "  - strides = 2\n",
    "- Batch normalization after each stack\n",
    "- Dropout layer after each stack\n",
    "  - dropout = 0.4\n",
    "- A residual layer circumventing each stack\n",
    "- A single dense layer\n",
    "\n",
    "**Test accuracy: 0.9953**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aTrH_FVEy5m9",
    "outputId": "1e4c8adb-5556-4ed6-db39-290266cbb32a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: model\n",
      "Total number of parameters: 513866\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)      (None, 28, 28, 1)    0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " sequential_21 (Sequential)     (None, 28, 28, 1)    0           ['sequential_7[3][0]']           \n",
      "                                                                                                  \n",
      " convA32 (Conv2D)               (None, 28, 28, 32)   320         ['sequential_21[5][0]']          \n",
      "                                                                                                  \n",
      " convA_norm32 (BatchNormalizati  (None, 28, 28, 32)  128         ['convA32[0][0]']                \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " convB32 (Conv2D)               (None, 28, 28, 32)   9248        ['convA_norm32[0][0]']           \n",
      "                                                                                                  \n",
      " convB_norm32 (BatchNormalizati  (None, 28, 28, 32)  128         ['convB32[0][0]']                \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " strides32 (Conv2D)             (None, 14, 14, 32)   9248        ['convB_norm32[0][0]']           \n",
      "                                                                                                  \n",
      " strides_norm32 (BatchNormaliza  (None, 14, 14, 32)  128         ['strides32[0][0]']              \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 14, 14, 32)   0           ['strides_norm32[0][0]']         \n",
      "                                                                                                  \n",
      " convR32 (Conv2D)               (None, 14, 14, 32)   64          ['sequential_21[5][0]']          \n",
      "                                                                                                  \n",
      " add32 (Add)                    (None, 14, 14, 32)   0           ['dropout[0][0]',                \n",
      "                                                                  'convR32[0][0]']                \n",
      "                                                                                                  \n",
      " convA64 (Conv2D)               (None, 14, 14, 64)   18496       ['add32[0][0]']                  \n",
      "                                                                                                  \n",
      " convA_norm64 (BatchNormalizati  (None, 14, 14, 64)  256         ['convA64[0][0]']                \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " convB64 (Conv2D)               (None, 14, 14, 64)   36928       ['convA_norm64[0][0]']           \n",
      "                                                                                                  \n",
      " convB_norm64 (BatchNormalizati  (None, 14, 14, 64)  256         ['convB64[0][0]']                \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " strides64 (Conv2D)             (None, 7, 7, 64)     36928       ['convB_norm64[0][0]']           \n",
      "                                                                                                  \n",
      " strides_norm64 (BatchNormaliza  (None, 7, 7, 64)    256         ['strides64[0][0]']              \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 7, 7, 64)     0           ['strides_norm64[0][0]']         \n",
      "                                                                                                  \n",
      " convR64 (Conv2D)               (None, 7, 7, 64)     2112        ['add32[0][0]']                  \n",
      "                                                                                                  \n",
      " add64 (Add)                    (None, 7, 7, 64)     0           ['dropout_1[0][0]',              \n",
      "                                                                  'convR64[0][0]']                \n",
      "                                                                                                  \n",
      " convA128 (Conv2D)              (None, 7, 7, 128)    73856       ['add64[0][0]']                  \n",
      "                                                                                                  \n",
      " convA_norm128 (BatchNormalizat  (None, 7, 7, 128)   512         ['convA128[0][0]']               \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " convB128 (Conv2D)              (None, 7, 7, 128)    147584      ['convA_norm128[0][0]']          \n",
      "                                                                                                  \n",
      " convB_norm128 (BatchNormalizat  (None, 7, 7, 128)   512         ['convB128[0][0]']               \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " strides128 (Conv2D)            (None, 4, 4, 128)    147584      ['convB_norm128[0][0]']          \n",
      "                                                                                                  \n",
      " strides_norm128 (BatchNormaliz  (None, 4, 4, 128)   512         ['strides128[0][0]']             \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 4, 128)    0           ['strides_norm128[0][0]']        \n",
      "                                                                                                  \n",
      " convR128 (Conv2D)              (None, 4, 4, 128)    8320        ['add64[0][0]']                  \n",
      "                                                                                                  \n",
      " add128 (Add)                   (None, 4, 4, 128)    0           ['dropout_2[0][0]',              \n",
      "                                                                  'convR128[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['add128[0][0]']                 \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 10)           20490       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 513,866\n",
      "Trainable params: 512,522\n",
      "Non-trainable params: 1,344\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "782/782 [==============================] - 14s 15ms/step - loss: 0.4061 - accuracy: 0.8902 - val_loss: 0.1238 - val_accuracy: 0.9695\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.1585 - accuracy: 0.9565 - val_loss: 0.1032 - val_accuracy: 0.9778\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.1209 - accuracy: 0.9670 - val_loss: 0.0702 - val_accuracy: 0.9832\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.1069 - accuracy: 0.9703 - val_loss: 0.0646 - val_accuracy: 0.9828\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0906 - accuracy: 0.9751 - val_loss: 0.0650 - val_accuracy: 0.9852\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0839 - accuracy: 0.9767 - val_loss: 0.0462 - val_accuracy: 0.9877\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0745 - accuracy: 0.9790 - val_loss: 0.0558 - val_accuracy: 0.9885\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0714 - accuracy: 0.9803 - val_loss: 0.0469 - val_accuracy: 0.9890\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0640 - accuracy: 0.9821 - val_loss: 0.0430 - val_accuracy: 0.9902\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0639 - accuracy: 0.9831 - val_loss: 0.0456 - val_accuracy: 0.9896\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0594 - accuracy: 0.9831 - val_loss: 0.0442 - val_accuracy: 0.9896\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0556 - accuracy: 0.9847 - val_loss: 0.0428 - val_accuracy: 0.9897\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0529 - accuracy: 0.9854 - val_loss: 0.0535 - val_accuracy: 0.9880\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0516 - accuracy: 0.9858 - val_loss: 0.0417 - val_accuracy: 0.9913\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0485 - accuracy: 0.9862 - val_loss: 0.0362 - val_accuracy: 0.9926\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0489 - accuracy: 0.9862 - val_loss: 0.0379 - val_accuracy: 0.9912\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0456 - accuracy: 0.9874 - val_loss: 0.0339 - val_accuracy: 0.9916\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0429 - accuracy: 0.9878 - val_loss: 0.0371 - val_accuracy: 0.9914\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0445 - accuracy: 0.9877 - val_loss: 0.0372 - val_accuracy: 0.9917\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0416 - accuracy: 0.9881 - val_loss: 0.0304 - val_accuracy: 0.9933\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0423 - accuracy: 0.9882 - val_loss: 0.0273 - val_accuracy: 0.9928\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0394 - accuracy: 0.9884 - val_loss: 0.0318 - val_accuracy: 0.9923\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0407 - accuracy: 0.9882 - val_loss: 0.0345 - val_accuracy: 0.9923\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0387 - accuracy: 0.9885 - val_loss: 0.0287 - val_accuracy: 0.9931\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0389 - accuracy: 0.9886 - val_loss: 0.0297 - val_accuracy: 0.9933\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 11s 15ms/step - loss: 0.0355 - accuracy: 0.9899 - val_loss: 0.0382 - val_accuracy: 0.9911\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0374 - accuracy: 0.9896 - val_loss: 0.0354 - val_accuracy: 0.9922\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0340 - accuracy: 0.9902 - val_loss: 0.0308 - val_accuracy: 0.9915\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0341 - accuracy: 0.9900 - val_loss: 0.0386 - val_accuracy: 0.9919\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.0414 - val_accuracy: 0.9912\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0312 - accuracy: 0.9913 - val_loss: 0.0354 - val_accuracy: 0.9931\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0300 - accuracy: 0.9910 - val_loss: 0.0304 - val_accuracy: 0.9926\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0336 - accuracy: 0.9907 - val_loss: 0.0358 - val_accuracy: 0.9926\n",
      "Epoch 34/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0303 - accuracy: 0.9914 - val_loss: 0.0266 - val_accuracy: 0.9940\n",
      "Epoch 35/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0305 - accuracy: 0.9915 - val_loss: 0.0257 - val_accuracy: 0.9943\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0302 - accuracy: 0.9916 - val_loss: 0.0339 - val_accuracy: 0.9936\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0277 - accuracy: 0.9918 - val_loss: 0.0296 - val_accuracy: 0.9945\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.0282 - val_accuracy: 0.9931\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0298 - accuracy: 0.9917 - val_loss: 0.0353 - val_accuracy: 0.9928\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 0.0278 - val_accuracy: 0.9948\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0286 - accuracy: 0.9923 - val_loss: 0.0251 - val_accuracy: 0.9949\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0255 - accuracy: 0.9926 - val_loss: 0.0317 - val_accuracy: 0.9932\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0271 - accuracy: 0.9922 - val_loss: 0.0360 - val_accuracy: 0.9932\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0275 - accuracy: 0.9919 - val_loss: 0.0343 - val_accuracy: 0.9929\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0286 - accuracy: 0.9917 - val_loss: 0.0342 - val_accuracy: 0.9931\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.0326 - val_accuracy: 0.9933\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0243 - accuracy: 0.9928 - val_loss: 0.0303 - val_accuracy: 0.9937\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0267 - accuracy: 0.9921 - val_loss: 0.0331 - val_accuracy: 0.9931\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0251 - accuracy: 0.9925 - val_loss: 0.0280 - val_accuracy: 0.9937\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0245 - accuracy: 0.9930 - val_loss: 0.0435 - val_accuracy: 0.9921\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0239 - accuracy: 0.9930 - val_loss: 0.0279 - val_accuracy: 0.9943\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0249 - val_accuracy: 0.9945\n",
      "Epoch 53/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0257 - accuracy: 0.9929 - val_loss: 0.0300 - val_accuracy: 0.9938\n",
      "Epoch 54/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 0.0345 - val_accuracy: 0.9937\n",
      "Epoch 55/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0342 - val_accuracy: 0.9932\n",
      "Epoch 56/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0241 - accuracy: 0.9935 - val_loss: 0.0323 - val_accuracy: 0.9939\n",
      "Epoch 57/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0235 - accuracy: 0.9929 - val_loss: 0.0310 - val_accuracy: 0.9938\n",
      "Epoch 58/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0244 - accuracy: 0.9930 - val_loss: 0.0307 - val_accuracy: 0.9940\n",
      "Epoch 59/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0221 - accuracy: 0.9930 - val_loss: 0.0317 - val_accuracy: 0.9934\n",
      "Epoch 60/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 0.0399 - val_accuracy: 0.9933\n",
      "Epoch 61/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.0307 - val_accuracy: 0.9941\n",
      "Epoch 62/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0228 - accuracy: 0.9935 - val_loss: 0.0382 - val_accuracy: 0.9931\n",
      "Epoch 63/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.0374 - val_accuracy: 0.9923\n",
      "Epoch 64/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.0324 - val_accuracy: 0.9932\n",
      "Epoch 65/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0230 - accuracy: 0.9936 - val_loss: 0.0356 - val_accuracy: 0.9932\n",
      "Epoch 66/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0312 - val_accuracy: 0.9926\n",
      "Epoch 67/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0214 - accuracy: 0.9937 - val_loss: 0.0257 - val_accuracy: 0.9945\n",
      "Epoch 68/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.0287 - val_accuracy: 0.9933\n",
      "Epoch 69/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0297 - val_accuracy: 0.9938\n",
      "Epoch 70/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.0418 - val_accuracy: 0.9917\n",
      "Epoch 71/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 0.0288 - val_accuracy: 0.9945\n",
      "Epoch 72/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.0247 - val_accuracy: 0.9941\n",
      "Epoch 73/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.0301 - val_accuracy: 0.9947\n",
      "Epoch 74/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.0281 - val_accuracy: 0.9941\n",
      "Epoch 75/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0346 - val_accuracy: 0.9928\n",
      "Epoch 76/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 0.0324 - val_accuracy: 0.9953\n",
      "Epoch 77/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.0348 - val_accuracy: 0.9936\n",
      "Epoch 78/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.0324 - val_accuracy: 0.9934\n",
      "Epoch 79/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.0360 - val_accuracy: 0.9940\n",
      "Epoch 80/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 0.0363 - val_accuracy: 0.9948\n",
      "Epoch 81/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.0496 - val_accuracy: 0.9914\n",
      "Epoch 82/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0199 - accuracy: 0.9946 - val_loss: 0.0286 - val_accuracy: 0.9940\n",
      "Epoch 83/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.0262 - val_accuracy: 0.9952\n",
      "Epoch 84/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0186 - accuracy: 0.9948 - val_loss: 0.0338 - val_accuracy: 0.9938\n",
      "Epoch 85/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 0.0348 - val_accuracy: 0.9931\n",
      "Epoch 86/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 0.0345 - val_accuracy: 0.9942\n",
      "Epoch 87/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.0574 - val_accuracy: 0.9909\n",
      "Epoch 88/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.0293 - val_accuracy: 0.9950\n",
      "Epoch 89/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.0337 - val_accuracy: 0.9949\n",
      "Epoch 90/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0203 - accuracy: 0.9946 - val_loss: 0.0303 - val_accuracy: 0.9957\n",
      "Epoch 91/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0343 - val_accuracy: 0.9943\n",
      "Epoch 92/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.0277 - val_accuracy: 0.9949\n",
      "Epoch 93/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 0.0372 - val_accuracy: 0.9929\n",
      "Epoch 94/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0327 - val_accuracy: 0.9942\n",
      "Epoch 95/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.0558 - val_accuracy: 0.9895\n",
      "Epoch 96/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0178 - accuracy: 0.9950 - val_loss: 0.0293 - val_accuracy: 0.9941\n",
      "Epoch 97/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.0305 - val_accuracy: 0.9946\n",
      "Epoch 98/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 0.0278 - val_accuracy: 0.9947\n",
      "Epoch 99/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.0549 - val_accuracy: 0.9928\n",
      "Epoch 100/100\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 0.0191 - accuracy: 0.9948 - val_loss: 0.0311 - val_accuracy: 0.9946\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9952999949455261\n"
     ]
    }
   ],
   "source": [
    "# UNCOMMENT TO RUN THIS MODEL\n",
    "\n",
    "# model_name=\"data_augmentation_conv_stack\"\n",
    "# inputs = keras.Input(shape=(28,28,1), name=\"inputs\")\n",
    "\n",
    "# x = data_augmentation(inputs)\n",
    "# x = resize_and_rescale(x)\n",
    "\n",
    "# filters = [32, 64, 128]\n",
    "# for i,f in enumerate(filters):\n",
    "#     residual = x\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\", name=\"convA\"+str(f)) (x)\n",
    "#     x = layers.BatchNormalization(name=\"convA_norm\"+str(f)) (x)\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\", name=\"convB\"+str(f)) (x)\n",
    "#     x = layers.BatchNormalization(name=\"convB_norm\"+str(f)) (x)\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", strides=2, activation=\"relu\", name=\"strides\"+str(f)) (x)\n",
    "#     x = layers.BatchNormalization(name=\"strides_norm\"+str(f)) (x)\n",
    "#     x = layers.Dropout(0.4) (x)\n",
    "#     residual = layers.Conv2D(f, 1, padding=\"same\", strides=2, name=\"convR\"+str(f)) (residual)\n",
    "#     x = layers.add([x, residual], name=\"add\"+str(f))\n",
    "\n",
    "# x = layers.Flatten(name=\"flatten\") (x)\n",
    "# outputs = layers.Dense(10, activation=\"softmax\", name=\"outputs\") (x)\n",
    "\n",
    "# new_model(inputs, outputs,summary=True, plot=True, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhVjqzi0vczK"
   },
   "source": [
    "## Remove the second convolutional layer of each stack\n",
    "\n",
    "- Data augmentation layer\n",
    "    - Random rotation\n",
    "    - Random zoom\n",
    "- ***3 convolutional layers***\n",
    "  - kernel size = 3\n",
    "  - number of filters = 32, 64 and 128\n",
    "- Conv. layer with strides = 2 instead of max pooling layers, after each conv layer\n",
    "  - strides = 2\n",
    "- Batch normalization after each conv layer\n",
    "- Dropout layer after each conv layer\n",
    "  - dropout = 0.4\n",
    "- A residual layer circumventing each stack\n",
    "- A single dense layer\n",
    "\n",
    "**Test accuracy: 0.9957**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JmXA17wQ-UeB",
    "outputId": "5102018a-a299-495b-d168-89a37510996b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: model\n",
      "Total number of parameters: 319210\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)      (None, 28, 28, 1)    0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " sequential_21 (Sequential)     (None, 28, 28, 1)    0           ['sequential_7[5][0]']           \n",
      "                                                                                                  \n",
      " conv32 (Conv2D)                (None, 28, 28, 32)   320         ['sequential_21[7][0]']          \n",
      "                                                                                                  \n",
      " conv_norm32 (BatchNormalizatio  (None, 28, 28, 32)  128         ['conv32[0][0]']                 \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " strides32 (Conv2D)             (None, 14, 14, 32)   9248        ['conv_norm32[0][0]']            \n",
      "                                                                                                  \n",
      " strides_norm32 (BatchNormaliza  (None, 14, 14, 32)  128         ['strides32[0][0]']              \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 14, 14, 32)   0           ['strides_norm32[0][0]']         \n",
      "                                                                                                  \n",
      " convR32 (Conv2D)               (None, 14, 14, 32)   64          ['sequential_21[7][0]']          \n",
      "                                                                                                  \n",
      " add32 (Add)                    (None, 14, 14, 32)   0           ['dropout_3[0][0]',              \n",
      "                                                                  'convR32[0][0]']                \n",
      "                                                                                                  \n",
      " conv64 (Conv2D)                (None, 14, 14, 64)   18496       ['add32[0][0]']                  \n",
      "                                                                                                  \n",
      " conv_norm64 (BatchNormalizatio  (None, 14, 14, 64)  256         ['conv64[0][0]']                 \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " strides64 (Conv2D)             (None, 7, 7, 64)     36928       ['conv_norm64[0][0]']            \n",
      "                                                                                                  \n",
      " strides_norm64 (BatchNormaliza  (None, 7, 7, 64)    256         ['strides64[0][0]']              \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 7, 7, 64)     0           ['strides_norm64[0][0]']         \n",
      "                                                                                                  \n",
      " convR64 (Conv2D)               (None, 7, 7, 64)     2112        ['add32[0][0]']                  \n",
      "                                                                                                  \n",
      " add64 (Add)                    (None, 7, 7, 64)     0           ['dropout_4[0][0]',              \n",
      "                                                                  'convR64[0][0]']                \n",
      "                                                                                                  \n",
      " conv128 (Conv2D)               (None, 7, 7, 128)    73856       ['add64[0][0]']                  \n",
      "                                                                                                  \n",
      " conv_norm128 (BatchNormalizati  (None, 7, 7, 128)   512         ['conv128[0][0]']                \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " strides128 (Conv2D)            (None, 4, 4, 128)    147584      ['conv_norm128[0][0]']           \n",
      "                                                                                                  \n",
      " strides_norm128 (BatchNormaliz  (None, 4, 4, 128)   512         ['strides128[0][0]']             \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 4, 4, 128)    0           ['strides_norm128[0][0]']        \n",
      "                                                                                                  \n",
      " convR128 (Conv2D)              (None, 4, 4, 128)    8320        ['add64[0][0]']                  \n",
      "                                                                                                  \n",
      " add128 (Add)                   (None, 4, 4, 128)    0           ['dropout_5[0][0]',              \n",
      "                                                                  'convR128[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['add128[0][0]']                 \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 10)           20490       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 319,210\n",
      "Trainable params: 318,314\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "782/782 [==============================] - 10s 11ms/step - loss: 0.4376 - accuracy: 0.8799 - val_loss: 0.1667 - val_accuracy: 0.9589\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1790 - accuracy: 0.9494 - val_loss: 0.1045 - val_accuracy: 0.9733\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1428 - accuracy: 0.9608 - val_loss: 0.0676 - val_accuracy: 0.9815\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1245 - accuracy: 0.9654 - val_loss: 0.0565 - val_accuracy: 0.9843\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.1067 - accuracy: 0.9700 - val_loss: 0.0517 - val_accuracy: 0.9875\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0978 - accuracy: 0.9727 - val_loss: 0.0469 - val_accuracy: 0.9876\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0921 - accuracy: 0.9741 - val_loss: 0.0562 - val_accuracy: 0.9867\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0891 - accuracy: 0.9754 - val_loss: 0.0492 - val_accuracy: 0.9879\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0810 - accuracy: 0.9774 - val_loss: 0.0479 - val_accuracy: 0.9874\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0806 - accuracy: 0.9781 - val_loss: 0.0601 - val_accuracy: 0.9863\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0760 - accuracy: 0.9785 - val_loss: 0.0532 - val_accuracy: 0.9863\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0733 - accuracy: 0.9796 - val_loss: 0.0437 - val_accuracy: 0.9891\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0668 - accuracy: 0.9812 - val_loss: 0.0346 - val_accuracy: 0.9899\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0651 - accuracy: 0.9819 - val_loss: 0.0456 - val_accuracy: 0.9888\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0630 - accuracy: 0.9822 - val_loss: 0.0344 - val_accuracy: 0.9911\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0627 - accuracy: 0.9822 - val_loss: 0.0353 - val_accuracy: 0.9915\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0607 - accuracy: 0.9832 - val_loss: 0.0443 - val_accuracy: 0.9905\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0581 - accuracy: 0.9846 - val_loss: 0.0344 - val_accuracy: 0.9916\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0566 - accuracy: 0.9841 - val_loss: 0.0397 - val_accuracy: 0.9905\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0553 - accuracy: 0.9841 - val_loss: 0.0326 - val_accuracy: 0.9919\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0538 - accuracy: 0.9843 - val_loss: 0.0351 - val_accuracy: 0.9917\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0548 - accuracy: 0.9844 - val_loss: 0.0330 - val_accuracy: 0.9925\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0503 - accuracy: 0.9857 - val_loss: 0.0354 - val_accuracy: 0.9908\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0488 - accuracy: 0.9857 - val_loss: 0.0322 - val_accuracy: 0.9926\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0509 - accuracy: 0.9857 - val_loss: 0.0328 - val_accuracy: 0.9925\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0471 - accuracy: 0.9861 - val_loss: 0.0412 - val_accuracy: 0.9908\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0493 - accuracy: 0.9857 - val_loss: 0.0514 - val_accuracy: 0.9894\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0430 - accuracy: 0.9875 - val_loss: 0.0301 - val_accuracy: 0.9938\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0476 - accuracy: 0.9864 - val_loss: 0.0321 - val_accuracy: 0.9931\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0435 - accuracy: 0.9873 - val_loss: 0.0289 - val_accuracy: 0.9929\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0431 - accuracy: 0.9870 - val_loss: 0.0285 - val_accuracy: 0.9934\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0442 - accuracy: 0.9878 - val_loss: 0.0358 - val_accuracy: 0.9911\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0433 - accuracy: 0.9877 - val_loss: 0.0304 - val_accuracy: 0.9921\n",
      "Epoch 34/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0435 - accuracy: 0.9877 - val_loss: 0.0339 - val_accuracy: 0.9929\n",
      "Epoch 35/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0433 - accuracy: 0.9877 - val_loss: 0.0323 - val_accuracy: 0.9916\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0433 - accuracy: 0.9878 - val_loss: 0.0320 - val_accuracy: 0.9925\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0414 - accuracy: 0.9879 - val_loss: 0.0289 - val_accuracy: 0.9941\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0395 - accuracy: 0.9885 - val_loss: 0.0322 - val_accuracy: 0.9928\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0403 - accuracy: 0.9879 - val_loss: 0.0311 - val_accuracy: 0.9932\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0361 - accuracy: 0.9890 - val_loss: 0.0491 - val_accuracy: 0.9912\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0390 - accuracy: 0.9882 - val_loss: 0.0302 - val_accuracy: 0.9928\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0395 - accuracy: 0.9883 - val_loss: 0.0288 - val_accuracy: 0.9936\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0367 - accuracy: 0.9893 - val_loss: 0.0290 - val_accuracy: 0.9936\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.0250 - val_accuracy: 0.9938\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0364 - accuracy: 0.9893 - val_loss: 0.0269 - val_accuracy: 0.9941\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0373 - accuracy: 0.9888 - val_loss: 0.0342 - val_accuracy: 0.9930\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0392 - accuracy: 0.9891 - val_loss: 0.0232 - val_accuracy: 0.9942\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0350 - accuracy: 0.9895 - val_loss: 0.0256 - val_accuracy: 0.9946\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0336 - accuracy: 0.9894 - val_loss: 0.0329 - val_accuracy: 0.9926\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0368 - accuracy: 0.9895 - val_loss: 0.0304 - val_accuracy: 0.9939\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0338 - accuracy: 0.9900 - val_loss: 0.0253 - val_accuracy: 0.9940\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0358 - accuracy: 0.9892 - val_loss: 0.0286 - val_accuracy: 0.9941\n",
      "Epoch 53/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0342 - accuracy: 0.9902 - val_loss: 0.0295 - val_accuracy: 0.9935\n",
      "Epoch 54/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 0.0260 - val_accuracy: 0.9940\n",
      "Epoch 55/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0326 - accuracy: 0.9899 - val_loss: 0.0337 - val_accuracy: 0.9917\n",
      "Epoch 56/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0326 - accuracy: 0.9900 - val_loss: 0.0336 - val_accuracy: 0.9926\n",
      "Epoch 57/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0316 - accuracy: 0.9901 - val_loss: 0.0355 - val_accuracy: 0.9898\n",
      "Epoch 58/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0330 - accuracy: 0.9898 - val_loss: 0.0275 - val_accuracy: 0.9942\n",
      "Epoch 59/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0346 - accuracy: 0.9902 - val_loss: 0.0278 - val_accuracy: 0.9940\n",
      "Epoch 60/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0324 - accuracy: 0.9900 - val_loss: 0.0284 - val_accuracy: 0.9944\n",
      "Epoch 61/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0313 - accuracy: 0.9908 - val_loss: 0.0374 - val_accuracy: 0.9924\n",
      "Epoch 62/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0316 - accuracy: 0.9907 - val_loss: 0.0342 - val_accuracy: 0.9913\n",
      "Epoch 63/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0315 - accuracy: 0.9910 - val_loss: 0.0317 - val_accuracy: 0.9931\n",
      "Epoch 64/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0316 - accuracy: 0.9904 - val_loss: 0.0289 - val_accuracy: 0.9936\n",
      "Epoch 65/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0305 - accuracy: 0.9911 - val_loss: 0.0286 - val_accuracy: 0.9935\n",
      "Epoch 66/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0307 - accuracy: 0.9907 - val_loss: 0.0343 - val_accuracy: 0.9923\n",
      "Epoch 67/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0317 - accuracy: 0.9902 - val_loss: 0.0250 - val_accuracy: 0.9947\n",
      "Epoch 68/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0308 - accuracy: 0.9908 - val_loss: 0.0291 - val_accuracy: 0.9939\n",
      "Epoch 69/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0289 - accuracy: 0.9914 - val_loss: 0.0369 - val_accuracy: 0.9907\n",
      "Epoch 70/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0317 - accuracy: 0.9905 - val_loss: 0.0263 - val_accuracy: 0.9942\n",
      "Epoch 71/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0298 - accuracy: 0.9908 - val_loss: 0.0250 - val_accuracy: 0.9947\n",
      "Epoch 72/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0315 - accuracy: 0.9911 - val_loss: 0.0280 - val_accuracy: 0.9937\n",
      "Epoch 73/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.0329 - val_accuracy: 0.9936\n",
      "Epoch 74/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0287 - accuracy: 0.9914 - val_loss: 0.0278 - val_accuracy: 0.9940\n",
      "Epoch 75/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0296 - accuracy: 0.9913 - val_loss: 0.0272 - val_accuracy: 0.9948\n",
      "Epoch 76/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0299 - accuracy: 0.9910 - val_loss: 0.0235 - val_accuracy: 0.9943\n",
      "Epoch 77/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0286 - accuracy: 0.9916 - val_loss: 0.0283 - val_accuracy: 0.9936\n",
      "Epoch 78/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0299 - accuracy: 0.9913 - val_loss: 0.0287 - val_accuracy: 0.9941\n",
      "Epoch 79/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.0264 - val_accuracy: 0.9938\n",
      "Epoch 80/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.0255 - val_accuracy: 0.9943\n",
      "Epoch 81/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0294 - accuracy: 0.9910 - val_loss: 0.0244 - val_accuracy: 0.9948\n",
      "Epoch 82/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0275 - accuracy: 0.9914 - val_loss: 0.0252 - val_accuracy: 0.9943\n",
      "Epoch 83/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 0.0246 - val_accuracy: 0.9939\n",
      "Epoch 84/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0284 - accuracy: 0.9915 - val_loss: 0.0311 - val_accuracy: 0.9944\n",
      "Epoch 85/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.0226 - val_accuracy: 0.9954\n",
      "Epoch 86/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0283 - accuracy: 0.9918 - val_loss: 0.0343 - val_accuracy: 0.9929\n",
      "Epoch 87/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0283 - accuracy: 0.9918 - val_loss: 0.0346 - val_accuracy: 0.9936\n",
      "Epoch 88/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0293 - accuracy: 0.9918 - val_loss: 0.0337 - val_accuracy: 0.9934\n",
      "Epoch 89/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0271 - accuracy: 0.9918 - val_loss: 0.0302 - val_accuracy: 0.9941\n",
      "Epoch 90/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 0.0317 - val_accuracy: 0.9938\n",
      "Epoch 91/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0277 - accuracy: 0.9919 - val_loss: 0.0274 - val_accuracy: 0.9945\n",
      "Epoch 92/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0271 - accuracy: 0.9914 - val_loss: 0.0359 - val_accuracy: 0.9940\n",
      "Epoch 93/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 0.0317 - val_accuracy: 0.9945\n",
      "Epoch 94/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.0379 - val_accuracy: 0.9923\n",
      "Epoch 95/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0254 - accuracy: 0.9925 - val_loss: 0.0299 - val_accuracy: 0.9943\n",
      "Epoch 96/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0284 - accuracy: 0.9917 - val_loss: 0.0338 - val_accuracy: 0.9940\n",
      "Epoch 97/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 0.0263 - val_accuracy: 0.9943\n",
      "Epoch 98/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0291 - accuracy: 0.9920 - val_loss: 0.0273 - val_accuracy: 0.9941\n",
      "Epoch 99/100\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.0276 - accuracy: 0.9920 - val_loss: 0.0235 - val_accuracy: 0.9941\n",
      "Epoch 100/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0273 - accuracy: 0.9920 - val_loss: 0.0281 - val_accuracy: 0.9936\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9957000017166138\n"
     ]
    }
   ],
   "source": [
    "# UNCOMMENT TO RUN THIS MODEL\n",
    "\n",
    "# model_name=\"data_augmentation_single_conv\"\n",
    "\n",
    "# inputs = keras.Input(shape=(28,28,1), name=\"inputs\")\n",
    "\n",
    "# x = data_augmentation(inputs)\n",
    "# x = resize_and_rescale(x)\n",
    "\n",
    "# filters = [32, 64, 128]\n",
    "# for i,f in enumerate(filters):\n",
    "#     residual = x\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\", name=\"conv\"+str(f)) (x)\n",
    "#     x = layers.BatchNormalization(name=\"conv_norm\"+str(f)) (x)\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", strides=2, activation=\"relu\", name=\"strides\"+str(f)) (x)\n",
    "#     x = layers.BatchNormalization(name=\"strides_norm\"+str(f)) (x)\n",
    "#     x = layers.Dropout(0.4) (x)\n",
    "#     residual = layers.Conv2D(f, 1, padding=\"same\", strides=2, name=\"convR\"+str(f)) (residual)\n",
    "#     x = layers.add([x, residual], name=\"add\"+str(f))\n",
    "\n",
    "# x = layers.Flatten(name=\"flatten\") (x)\n",
    "# outputs = layers.Dense(10, activation=\"softmax\", name=\"outputs\") (x)\n",
    "\n",
    "# new_model(inputs, outputs,summary=True, plot=True, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiP-imoLwGF7"
   },
   "source": [
    "## Add a hidden dense layer\n",
    "\n",
    "- Data augmentation layer\n",
    "    - Random rotation\n",
    "    - Random zoom\n",
    "- 3 convolutional layers\n",
    "  - kernel size = 3\n",
    "  - number of filters = 32, 64 and 128\n",
    "- Conv. layer with strides = 2 instead of max pooling layers, after each conv layer\n",
    "  - strides = 2\n",
    "- Batch normalization after each conv layer\n",
    "- Dropout layer after each conv layer\n",
    "  - dropout = 0.4\n",
    "- A residual layer circumventing each stack\n",
    "- ***Two dense layers***\n",
    "  - ***hidden - 128 neurons***\n",
    "  - output - 10 neurons\n",
    "\n",
    "**Test accuracy: 0.9902**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "guWzN7pDCccQ",
    "outputId": "097424f7-2784-4e8a-a4df-dbb4bdc1854b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: model\n",
      "Total number of parameters: 562282\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)      (None, 28, 28, 1)    0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " sequential_21 (Sequential)     (None, 28, 28, 1)    0           ['sequential_7[6][0]']           \n",
      "                                                                                                  \n",
      " conv32 (Conv2D)                (None, 28, 28, 32)   320         ['sequential_21[8][0]']          \n",
      "                                                                                                  \n",
      " conv_norm32 (BatchNormalizatio  (None, 28, 28, 32)  128         ['conv32[0][0]']                 \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " strides32 (Conv2D)             (None, 14, 14, 32)   9248        ['conv_norm32[0][0]']            \n",
      "                                                                                                  \n",
      " strides_norm32 (BatchNormaliza  (None, 14, 14, 32)  128         ['strides32[0][0]']              \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 14, 14, 32)   0           ['strides_norm32[0][0]']         \n",
      "                                                                                                  \n",
      " convR32 (Conv2D)               (None, 14, 14, 32)   64          ['sequential_21[8][0]']          \n",
      "                                                                                                  \n",
      " add32 (Add)                    (None, 14, 14, 32)   0           ['dropout[0][0]',                \n",
      "                                                                  'convR32[0][0]']                \n",
      "                                                                                                  \n",
      " conv64 (Conv2D)                (None, 14, 14, 64)   18496       ['add32[0][0]']                  \n",
      "                                                                                                  \n",
      " conv_norm64 (BatchNormalizatio  (None, 14, 14, 64)  256         ['conv64[0][0]']                 \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " strides64 (Conv2D)             (None, 7, 7, 64)     36928       ['conv_norm64[0][0]']            \n",
      "                                                                                                  \n",
      " strides_norm64 (BatchNormaliza  (None, 7, 7, 64)    256         ['strides64[0][0]']              \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 7, 7, 64)     0           ['strides_norm64[0][0]']         \n",
      "                                                                                                  \n",
      " convR64 (Conv2D)               (None, 7, 7, 64)     2112        ['add32[0][0]']                  \n",
      "                                                                                                  \n",
      " add64 (Add)                    (None, 7, 7, 64)     0           ['dropout_1[0][0]',              \n",
      "                                                                  'convR64[0][0]']                \n",
      "                                                                                                  \n",
      " conv128 (Conv2D)               (None, 7, 7, 128)    73856       ['add64[0][0]']                  \n",
      "                                                                                                  \n",
      " conv_norm128 (BatchNormalizati  (None, 7, 7, 128)   512         ['conv128[0][0]']                \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " strides128 (Conv2D)            (None, 4, 4, 128)    147584      ['conv_norm128[0][0]']           \n",
      "                                                                                                  \n",
      " strides_norm128 (BatchNormaliz  (None, 4, 4, 128)   512         ['strides128[0][0]']             \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 4, 128)    0           ['strides_norm128[0][0]']        \n",
      "                                                                                                  \n",
      " convR128 (Conv2D)              (None, 4, 4, 128)    8320        ['add64[0][0]']                  \n",
      "                                                                                                  \n",
      " add128 (Add)                   (None, 4, 4, 128)    0           ['dropout_2[0][0]',              \n",
      "                                                                  'convR128[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['add128[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          262272      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 10)           1290        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 562,282\n",
      "Trainable params: 561,386\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "782/782 [==============================] - 11s 12ms/step - loss: 0.5386 - accuracy: 0.8417 - val_loss: 0.2262 - val_accuracy: 0.9567\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.2509 - accuracy: 0.9333 - val_loss: 0.1124 - val_accuracy: 0.9741\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.2111 - accuracy: 0.9460 - val_loss: 0.1647 - val_accuracy: 0.9659\n",
      "Epoch 4/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1983 - accuracy: 0.9500 - val_loss: 0.0957 - val_accuracy: 0.9825\n",
      "Epoch 5/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1987 - accuracy: 0.9520 - val_loss: 0.0688 - val_accuracy: 0.9847\n",
      "Epoch 6/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1938 - accuracy: 0.9545 - val_loss: 0.0872 - val_accuracy: 0.9847\n",
      "Epoch 7/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1814 - accuracy: 0.9574 - val_loss: 0.1276 - val_accuracy: 0.9821\n",
      "Epoch 8/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1820 - accuracy: 0.9576 - val_loss: 0.0898 - val_accuracy: 0.9851\n",
      "Epoch 9/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1804 - accuracy: 0.9590 - val_loss: 0.0835 - val_accuracy: 0.9853\n",
      "Epoch 10/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1718 - accuracy: 0.9605 - val_loss: 0.0873 - val_accuracy: 0.9863\n",
      "Epoch 11/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1737 - accuracy: 0.9622 - val_loss: 0.0741 - val_accuracy: 0.9860\n",
      "Epoch 12/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1701 - accuracy: 0.9639 - val_loss: 0.0835 - val_accuracy: 0.9862\n",
      "Epoch 13/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1785 - accuracy: 0.9622 - val_loss: 0.0683 - val_accuracy: 0.9887\n",
      "Epoch 14/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1762 - accuracy: 0.9641 - val_loss: 0.0981 - val_accuracy: 0.9851\n",
      "Epoch 15/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1713 - accuracy: 0.9640 - val_loss: 0.1130 - val_accuracy: 0.9813\n",
      "Epoch 16/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1701 - accuracy: 0.9653 - val_loss: 0.0683 - val_accuracy: 0.9889\n",
      "Epoch 17/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1710 - accuracy: 0.9649 - val_loss: 0.0931 - val_accuracy: 0.9824\n",
      "Epoch 18/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1755 - accuracy: 0.9640 - val_loss: 0.0613 - val_accuracy: 0.9892\n",
      "Epoch 19/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1712 - accuracy: 0.9651 - val_loss: 0.0683 - val_accuracy: 0.9880\n",
      "Epoch 20/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1719 - accuracy: 0.9653 - val_loss: 0.0708 - val_accuracy: 0.9894\n",
      "Epoch 21/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1596 - accuracy: 0.9671 - val_loss: 0.1072 - val_accuracy: 0.9857\n",
      "Epoch 22/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1661 - accuracy: 0.9667 - val_loss: 0.0655 - val_accuracy: 0.9873\n",
      "Epoch 23/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1691 - accuracy: 0.9656 - val_loss: 0.0774 - val_accuracy: 0.9887\n",
      "Epoch 24/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1629 - accuracy: 0.9674 - val_loss: 0.0752 - val_accuracy: 0.9888\n",
      "Epoch 25/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1629 - accuracy: 0.9682 - val_loss: 0.0967 - val_accuracy: 0.9886\n",
      "Epoch 26/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1617 - accuracy: 0.9674 - val_loss: 0.0781 - val_accuracy: 0.9895\n",
      "Epoch 27/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1534 - accuracy: 0.9690 - val_loss: 0.0873 - val_accuracy: 0.9853\n",
      "Epoch 28/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1543 - accuracy: 0.9682 - val_loss: 0.0945 - val_accuracy: 0.9865\n",
      "Epoch 29/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1463 - accuracy: 0.9705 - val_loss: 0.0834 - val_accuracy: 0.9879\n",
      "Epoch 30/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1569 - accuracy: 0.9696 - val_loss: 0.0747 - val_accuracy: 0.9887\n",
      "Epoch 31/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1512 - accuracy: 0.9690 - val_loss: 0.0878 - val_accuracy: 0.9905\n",
      "Epoch 32/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1423 - accuracy: 0.9712 - val_loss: 0.0850 - val_accuracy: 0.9889\n",
      "Epoch 33/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1378 - accuracy: 0.9712 - val_loss: 0.0630 - val_accuracy: 0.9885\n",
      "Epoch 34/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1365 - accuracy: 0.9710 - val_loss: 0.0508 - val_accuracy: 0.9908\n",
      "Epoch 35/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1304 - accuracy: 0.9729 - val_loss: 0.0650 - val_accuracy: 0.9899\n",
      "Epoch 36/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1301 - accuracy: 0.9728 - val_loss: 0.0577 - val_accuracy: 0.9896\n",
      "Epoch 37/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1254 - accuracy: 0.9729 - val_loss: 0.0632 - val_accuracy: 0.9897\n",
      "Epoch 38/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1253 - accuracy: 0.9733 - val_loss: 0.0827 - val_accuracy: 0.9832\n",
      "Epoch 39/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1172 - accuracy: 0.9746 - val_loss: 0.0530 - val_accuracy: 0.9897\n",
      "Epoch 40/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1149 - accuracy: 0.9754 - val_loss: 0.0745 - val_accuracy: 0.9890\n",
      "Epoch 41/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1158 - accuracy: 0.9744 - val_loss: 0.0687 - val_accuracy: 0.9874\n",
      "Epoch 42/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1172 - accuracy: 0.9749 - val_loss: 0.0752 - val_accuracy: 0.9863\n",
      "Epoch 43/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1115 - accuracy: 0.9754 - val_loss: 0.0710 - val_accuracy: 0.9920\n",
      "Epoch 44/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1162 - accuracy: 0.9748 - val_loss: 0.0668 - val_accuracy: 0.9888\n",
      "Epoch 45/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1065 - accuracy: 0.9762 - val_loss: 0.0900 - val_accuracy: 0.9873\n",
      "Epoch 46/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1100 - accuracy: 0.9756 - val_loss: 0.0683 - val_accuracy: 0.9898\n",
      "Epoch 47/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1101 - accuracy: 0.9755 - val_loss: 0.0485 - val_accuracy: 0.9925\n",
      "Epoch 48/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1057 - accuracy: 0.9768 - val_loss: 0.0901 - val_accuracy: 0.9866\n",
      "Epoch 49/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1101 - accuracy: 0.9757 - val_loss: 0.0474 - val_accuracy: 0.9895\n",
      "Epoch 50/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0976 - accuracy: 0.9776 - val_loss: 0.0477 - val_accuracy: 0.9914\n",
      "Epoch 51/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1005 - accuracy: 0.9778 - val_loss: 0.0470 - val_accuracy: 0.9911\n",
      "Epoch 52/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0959 - accuracy: 0.9774 - val_loss: 0.0664 - val_accuracy: 0.9906\n",
      "Epoch 53/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1013 - accuracy: 0.9769 - val_loss: 0.0646 - val_accuracy: 0.9890\n",
      "Epoch 54/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0995 - accuracy: 0.9779 - val_loss: 0.0684 - val_accuracy: 0.9903\n",
      "Epoch 55/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0950 - accuracy: 0.9785 - val_loss: 0.0617 - val_accuracy: 0.9891\n",
      "Epoch 56/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0946 - accuracy: 0.9792 - val_loss: 0.0519 - val_accuracy: 0.9907\n",
      "Epoch 57/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0933 - accuracy: 0.9784 - val_loss: 0.0634 - val_accuracy: 0.9895\n",
      "Epoch 58/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.1030 - accuracy: 0.9772 - val_loss: 0.0544 - val_accuracy: 0.9919\n",
      "Epoch 59/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0953 - accuracy: 0.9793 - val_loss: 0.1396 - val_accuracy: 0.9831\n",
      "Epoch 60/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0983 - accuracy: 0.9789 - val_loss: 0.0777 - val_accuracy: 0.9902\n",
      "Epoch 61/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0922 - accuracy: 0.9793 - val_loss: 0.0556 - val_accuracy: 0.9899\n",
      "Epoch 62/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0963 - accuracy: 0.9792 - val_loss: 0.0630 - val_accuracy: 0.9900\n",
      "Epoch 63/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0930 - accuracy: 0.9794 - val_loss: 0.0572 - val_accuracy: 0.9907\n",
      "Epoch 64/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0945 - accuracy: 0.9791 - val_loss: 0.0945 - val_accuracy: 0.9891\n",
      "Epoch 65/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0976 - accuracy: 0.9785 - val_loss: 0.0529 - val_accuracy: 0.9898\n",
      "Epoch 66/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0953 - accuracy: 0.9791 - val_loss: 0.0944 - val_accuracy: 0.9906\n",
      "Epoch 67/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0998 - accuracy: 0.9781 - val_loss: 0.0582 - val_accuracy: 0.9909\n",
      "Epoch 68/100\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.0972 - accuracy: 0.9797 - val_loss: 0.0750 - val_accuracy: 0.9898\n",
      "Epoch 69/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0976 - accuracy: 0.9790 - val_loss: 0.0732 - val_accuracy: 0.9899\n",
      "Epoch 70/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0935 - accuracy: 0.9796 - val_loss: 0.0546 - val_accuracy: 0.9890\n",
      "Epoch 71/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0917 - accuracy: 0.9791 - val_loss: 0.0817 - val_accuracy: 0.9900\n",
      "Epoch 72/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0999 - accuracy: 0.9786 - val_loss: 0.0470 - val_accuracy: 0.9920\n",
      "Epoch 73/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0980 - accuracy: 0.9786 - val_loss: 0.0610 - val_accuracy: 0.9862\n",
      "Epoch 74/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0967 - accuracy: 0.9788 - val_loss: 0.0555 - val_accuracy: 0.9889\n",
      "Epoch 75/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0967 - accuracy: 0.9795 - val_loss: 0.0800 - val_accuracy: 0.9909\n",
      "Epoch 76/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0999 - accuracy: 0.9786 - val_loss: 0.0553 - val_accuracy: 0.9898\n",
      "Epoch 77/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1005 - accuracy: 0.9785 - val_loss: 0.0967 - val_accuracy: 0.9884\n",
      "Epoch 78/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0991 - accuracy: 0.9788 - val_loss: 0.0694 - val_accuracy: 0.9915\n",
      "Epoch 79/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1001 - accuracy: 0.9782 - val_loss: 0.0459 - val_accuracy: 0.9903\n",
      "Epoch 80/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0980 - accuracy: 0.9797 - val_loss: 0.0675 - val_accuracy: 0.9889\n",
      "Epoch 81/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0986 - accuracy: 0.9798 - val_loss: 0.0824 - val_accuracy: 0.9896\n",
      "Epoch 82/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0964 - accuracy: 0.9795 - val_loss: 0.0729 - val_accuracy: 0.9913\n",
      "Epoch 83/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1012 - accuracy: 0.9793 - val_loss: 0.0583 - val_accuracy: 0.9911\n",
      "Epoch 84/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1008 - accuracy: 0.9794 - val_loss: 0.1003 - val_accuracy: 0.9921\n",
      "Epoch 85/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1001 - accuracy: 0.9789 - val_loss: 0.0825 - val_accuracy: 0.9915\n",
      "Epoch 86/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1013 - accuracy: 0.9788 - val_loss: 0.0628 - val_accuracy: 0.9914\n",
      "Epoch 87/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1069 - accuracy: 0.9783 - val_loss: 0.0537 - val_accuracy: 0.9882\n",
      "Epoch 88/100\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.1013 - accuracy: 0.9791 - val_loss: 0.0530 - val_accuracy: 0.9913\n",
      "Epoch 89/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1049 - accuracy: 0.9774 - val_loss: 0.1127 - val_accuracy: 0.9907\n",
      "Epoch 90/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1039 - accuracy: 0.9789 - val_loss: 0.0648 - val_accuracy: 0.9853\n",
      "Epoch 91/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1095 - accuracy: 0.9783 - val_loss: 0.0850 - val_accuracy: 0.9918\n",
      "Epoch 92/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1097 - accuracy: 0.9780 - val_loss: 0.0647 - val_accuracy: 0.9892\n",
      "Epoch 93/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1035 - accuracy: 0.9796 - val_loss: 0.0785 - val_accuracy: 0.9905\n",
      "Epoch 94/100\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.1102 - accuracy: 0.9778 - val_loss: 0.0614 - val_accuracy: 0.9917\n",
      "Epoch 95/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1138 - accuracy: 0.9771 - val_loss: 0.1197 - val_accuracy: 0.9886\n",
      "Epoch 96/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1068 - accuracy: 0.9784 - val_loss: 0.0560 - val_accuracy: 0.9885\n",
      "Epoch 97/100\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.1108 - accuracy: 0.9775 - val_loss: 0.0935 - val_accuracy: 0.9915\n",
      "Epoch 98/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1055 - accuracy: 0.9790 - val_loss: 0.0570 - val_accuracy: 0.9918\n",
      "Epoch 99/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1090 - accuracy: 0.9772 - val_loss: 0.0624 - val_accuracy: 0.9877\n",
      "Epoch 100/100\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.1101 - accuracy: 0.9791 - val_loss: 0.1080 - val_accuracy: 0.9854\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9905999898910522\n"
     ]
    }
   ],
   "source": [
    "# UNCOMMENT TO RUN THIS MODEL\n",
    "\n",
    "# model_name=\"data_augmentation_two_dense\"\n",
    "\n",
    "# inputs = keras.Input(shape=(28,28,1), name=\"inputs\")\n",
    "\n",
    "# x = data_augmentation(inputs)\n",
    "# x = resize_and_rescale(x)\n",
    "\n",
    "# filters = [32, 64, 128]\n",
    "# for i,f in enumerate(filters):\n",
    "#     residual = x\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\", name=\"conv\"+str(f)) (x)\n",
    "#     x = layers.BatchNormalization(name=\"conv_norm\"+str(f)) (x)\n",
    "#     x = layers.Conv2D(f, 3, padding=\"same\", strides=2, activation=\"relu\", name=\"strides\"+str(f)) (x)\n",
    "#     x = layers.BatchNormalization(name=\"strides_norm\"+str(f)) (x)\n",
    "#     x = layers.Dropout(0.4) (x)\n",
    "#     residual = layers.Conv2D(f, 1, padding=\"same\", strides=2, name=\"convR\"+str(f)) (residual)\n",
    "#     x = layers.add([x, residual], name=\"add\"+str(f))\n",
    "\n",
    "# x = layers.Flatten(name=\"flatten\") (x)\n",
    "# x = layers.Dense(128, activation=\"relu\", name=\"dense\") (x)\n",
    "# x = layers.Dropout(0.4) (x)\n",
    "# outputs = layers.Dense(10, activation=\"softmax\", name=\"outputs\") (x)\n",
    "\n",
    "# new_model(inputs, outputs,summary=True, plot=True, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6dTZH9qxbxq"
   },
   "source": [
    "# Discussion\n",
    "\n",
    "## Seems to help:\n",
    "- Replacing max pooling with a convolutional layer with strides = 2\n",
    "- Adding droput\n",
    "- Adding bacth normalization\n",
    "- Adding data augmentation\n",
    "\n",
    "## Doesn't seem to help:\n",
    "- Adding a hidden dense layer\n",
    "- Adding a residual layer\n",
    "- Adding a second convolutional layer to each stack\n",
    "\n",
    "## Architecture that seems to work well:\n",
    "\n",
    "An architecture that should work fairly well seems to be:\n",
    "\n",
    "- Data augmentation layer\n",
    "- 3 convolutional layers\n",
    "- A conv. layer with strides = 2 instead of max pooling layers, after each conv layer\n",
    "- Batch normalization after each conv layer\n",
    "- Dropout layer after each conv layer\n",
    "- A single dense layer (output)\n",
    "\n",
    "## Work to do: find better hyperparameters\n",
    "\n",
    "But we haven't tested different hyperparameters for each layer. We got stuck with the ones we tried from intuition only. To find better hyperparameters we could try:\n",
    "- Remove the data augmentation, batch normalization and dropout layers.\n",
    "- Test different combinations of:\n",
    "    - Convolutional layer: number of filters, kernel size\n",
    "    - Different sizes of hidden layers\n",
    "    - Maybe try reinserting a second convolutional layer on each stack?\n",
    "    - Maybe try ADAM optimization instead of RMSPROP?\n",
    "\n",
    "Then we could train a new model with the proposed architecture and the \"optimal\" hyperparameters."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LykZK_G3YswF",
    "WESxeas3Y3OV",
    "409CTAUtsexV",
    "sqdNfmULljEW",
    "ZYD5uyofn8K9",
    "Imn3_ly-qRih",
    "s6y7HJW1tMHw",
    "a1TBpoSCtwpw",
    "8pPDTfLrukpo",
    "DD3aFw9cvAR-",
    "XhVjqzi0vczK",
    "ZiP-imoLwGF7"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
